{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c98e75f-b8c2-48dd-970d-4f1f2df2ded5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Carga del dataset desde CSV\n",
    "2. Exploración y limpieza inicial\n",
    "3. Transformaciones\n",
    "4. Preparación de datos para ML (indexado y ensamblado)\n",
    "5. Separación en train/test\n",
    "6. Entrenamiento del modelo\n",
    "7. Evaluación\n",
    "8. (Opcional) Guardado del modelo o predicciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba36f4b8-0119-49bc-b118-6a5daf7741f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+--------+---------+-----+\n|id_cliente|genero|edad|ingresos|     pais|churn|\n+----------+------+----+--------+---------+-----+\n|         1| mujer|  25|   32000|   España|    0|\n|         2|hombre|  45|   57000|   México|    1|\n|         3| mujer|  31|   43000|   España|    0|\n|         4|hombre|  29|   25000|    Chile|    0|\n|         5| mujer|  38|   72000|   México|    1|\n|         6|hombre|  35|   50000|Argentina|    0|\n|         7| mujer|  22|   28000|    Chile|    1|\n|         8|hombre|  39|   61000|   España|    0|\n|         9| mujer|  33|   46000|   México|    1|\n|        10|hombre|  28|   34000|Argentina|    0|\n+----------+------+----+--------+---------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# 1. Creamos el DataFrame desde datos simulados\n",
    "data = [\n",
    "    (1, \"mujer\", 25, 32000, \"España\", 0),\n",
    "    (2, \"hombre\", 45, 57000, \"México\", 1),\n",
    "    (3, \"mujer\", 31, 43000, \"España\", 0),\n",
    "    (4, \"hombre\", 29, 25000, \"Chile\", 0),\n",
    "    (5, \"mujer\", 38, 72000, \"México\", 1),\n",
    "    (6, \"hombre\", 35, 50000, \"Argentina\", 0),\n",
    "    (7, \"mujer\", 22, 28000, \"Chile\", 1),\n",
    "    (8, \"hombre\", 39, 61000, \"España\", 0),\n",
    "    (9, \"mujer\", 33, 46000, \"México\", 1),\n",
    "    (10, \"hombre\", 28, 34000, \"Argentina\", 0)\n",
    "]\n",
    "\n",
    "columnas = [\"id_cliente\", \"genero\", \"edad\", \"ingresos\", \"pais\", \"churn\"]\n",
    "df = spark.createDataFrame(data, columnas)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "612e9499-d876-4f7d-9f7a-e876daacf572",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id_cliente: long (nullable = true)\n |-- genero: string (nullable = true)\n |-- edad: long (nullable = true)\n |-- ingresos: long (nullable = true)\n |-- pais: string (nullable = true)\n |-- churn: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# 2. Inspeccionar el esquema\n",
    "\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9a73ee3-4112-4c4d-a69d-741e8d92d6ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+--------+\n|genero|genero_idx|     pais|pais_idx|\n+------+----------+---------+--------+\n| mujer|       1.0|   España|     0.0|\n|hombre|       0.0|   México|     1.0|\n| mujer|       1.0|   España|     0.0|\n|hombre|       0.0|    Chile|     3.0|\n| mujer|       1.0|   México|     1.0|\n|hombre|       0.0|Argentina|     2.0|\n| mujer|       1.0|    Chile|     3.0|\n|hombre|       0.0|   España|     0.0|\n| mujer|       1.0|   México|     1.0|\n|hombre|       0.0|Argentina|     2.0|\n+------+----------+---------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# 3. Indexar columnas categóricas\n",
    "# Usaremos StringIndexer para genero y pais.\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "index_genero = StringIndexer(inputCol=\"genero\", outputCol=\"genero_idx\")\n",
    "index_pais = StringIndexer(inputCol=\"pais\", outputCol=\"pais_idx\")\n",
    "\n",
    "df_indexado = index_genero.fit(df).transform(df)\n",
    "df_indexado = index_pais.fit(df_indexado).transform(df_indexado)\n",
    "df_indexado.select(\"genero\", \"genero_idx\", \"pais\", \"pais_idx\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "003563b4-0b60-4cf2-b0fc-23160c50f61e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n|features              |churn|\n+----------------------+-----+\n|[1.0,0.0,25.0,32000.0]|0    |\n|[0.0,1.0,45.0,57000.0]|1    |\n|[1.0,0.0,31.0,43000.0]|0    |\n|[0.0,3.0,29.0,25000.0]|0    |\n|[1.0,1.0,38.0,72000.0]|1    |\n|[0.0,2.0,35.0,50000.0]|0    |\n|[1.0,3.0,22.0,28000.0]|1    |\n|[0.0,0.0,39.0,61000.0]|0    |\n|[1.0,1.0,33.0,46000.0]|1    |\n|[0.0,2.0,28.0,34000.0]|0    |\n+----------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# 4. VectorAssembler para preparar las features\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "ensamblador = VectorAssembler(\n",
    "    inputCols=[\"genero_idx\", \"pais_idx\", \"edad\", \"ingresos\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "df_final = ensamblador.transform(df_indexado)\n",
    "df_final.select(\"features\", \"churn\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26fe59c0-64e1-450a-9deb-ef526655c7f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. Separar en train/test\n",
    "\n",
    "df_train, df_test = df_final.randomSplit([0.7, 0.3], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12153014-01f1-48f6-a8cc-91341e940bab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6. Entrenar modelo\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"churn\")\n",
    "modelo = lr.fit(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c20d9a45-7431-4fb1-9129-45d842b84fec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------------------------------------------+\n|churn|prediction|probability                                |\n+-----+----------+-------------------------------------------+\n|1    |0.0       |[0.9999910380582799,8.961941720064814E-6]  |\n|0    |0.0       |[0.918814419110038,0.08118558088996197]    |\n|0    |0.0       |[0.9999999998566282,1.4337175890943854E-10]|\n+-----+----------+-------------------------------------------+\n\nÁrea bajo la curva ROC: 0.5\n"
     ]
    }
   ],
   "source": [
    "# 7. Predecir y evaluar\n",
    "\n",
    "predicciones = modelo.transform(df_test)\n",
    "predicciones.select(\"churn\", \"prediction\", \"probability\").show(truncate=False)\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluador = BinaryClassificationEvaluator(labelCol=\"churn\", rawPredictionCol=\"rawPrediction\")\n",
    "roc_auc = evaluador.evaluate(predicciones)\n",
    "print(\"Área bajo la curva ROC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "725be6bb-7949-4ae5-ac99-7b31e5b01a95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 8. (Opcional) Guardar predicciones\n",
    "\n",
    "predicciones.select(\"id_cliente\", \"prediction\").write.mode(\"overwrite\").csv(\"/tmp/predicciones_clientes.csv\", header=True)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Proyecto",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
